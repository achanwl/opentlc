- name: Set default cluster-wide node selectors
  k8s:
    api_version: config.openshift.io/v1
    kind: Scheduler
    name: cluster
    definition:
      spec:
        defaultNodeSelector: node-role.kubernetes.io/worker=

- name: Bug workaround
  k8s:
    api_version: v1
    kind: Namespace
    name: openshift-cluster-csi-drivers
    definition:
      metadata:
        annotations:
          openshift.io/node-selector: ""

- name: Create debug project with tolerations for infra node debug pods
  k8s:
    state: present
    definition:
      apiVersion: v1
      kind: Namespace
      metadata:
        name: debug
        annotations:
          openshift.io/node-selector: ""
          scheduler.alpha.kubernetes.io/defaultTolerations: '[{"operator": "Exists"}]'

- name: Move cluster-monitoring stack to infra nodes and add persistent storage
  k8s:
    state: present
    definition: "{{ lookup('file', 'cluster-monitoring-config.yml') }}"

- name: Install Descheduler
  block:
    - name: Create openshift-kube-descheduler-operator namespace
      k8s:
        state: present
        definition:
          apiVersion: v1
          kind: Namespace
          metadata:
            name: openshift-kube-descheduler-operator
            annotations:
              openshift.io/node-selector: node-role.kubernetes.io/infra=
              scheduler.alpha.kubernetes.io/defaultTolerations: '[{"operator": "Exists"}]'
    - name: Create openshift-kube-descheduler-operator OperatorGroup
      k8s:
        state: present
        definition:
          apiVersion: operators.coreos.com/v1
          kind: OperatorGroup
          metadata:
            name: openshift-kube-descheduler-operator
            namespace: openshift-kube-descheduler-operator
          spec:
            targetNamespaces:
              - openshift-kube-descheduler-operator
    - name: Create cluster-kube-descheduler-operator Subscription
      k8s:
        state: present
        definition:
          apiVersion: operators.coreos.com/v1alpha1
          kind: Subscription
          metadata:
            name: cluster-kube-descheduler-operator
            namespace: openshift-kube-descheduler-operator
          spec:
            channel: "{{ clusterversion.resources[0].spec.channel.split('-')[1] }}"
            installPlanApproval: Automatic
            name: cluster-kube-descheduler-operator
            source: redhat-operators
            sourceNamespace: openshift-marketplace
        wait: yes
        wait_condition:
          reason: AllCatalogSourcesHealthy
          type: CatalogSourcesUnhealthy
          status: "False"
    - name: Get cluster-kube-descheduler-operator Subscription info
      k8s_info:
        api_version: operators.coreos.com/v1alpha1
        kind: Subscription
        name: cluster-kube-descheduler-operator
        namespace: openshift-kube-descheduler-operator
      register: kubedesch_sub_info
    - name: Wait for CSV creation
      debug:
        msg: "Waiting for CSV creation..."
      until: kubedesch_sub_info.resources[0].status.currentCSV is defined
      retries: 60
      delay: 1
    - name: Wait for successful clusterkubedescheduleroperator CSV
      k8s_info:
        api_version: operators.coreos.com/v1alpha1
        kind: ClusterServiceVersion
        name: "{{ kubedesch_sub_info.resources[0].status.currentCSV }}"
        namespace: openshift-kube-descheduler-operator
      register: kubedesch_csv_info
      until:
        - kubedesch_csv_info.resources[0].status.phase is defined
        - kubedesch_csv_info.resources[0].status.phase == "Succeeded"
      retries: 60
      delay: 1
    - name: Create KubeDescheduler
      k8s:
        state: present
        definition: "{{ lookup('file', 'kube-descheduler.yml') }}"

- name: Enable Autoscaler
  block:
    - name: Create ClusterAutoscaler
      k8s:
        state: present
        definition:
          apiVersion: autoscaling.openshift.io/v1
          kind: ClusterAutoscaler
          metadata:
            name: default
          spec:
            podPriorityThreshold: -10
            resourceLimits:
              maxNodesTotal: 21
              cores:
                min: 2
                max: 16
              memory:
                min: 8
                max: 64
            scaleDown:
              enabled: true
    - name: Create MachineAutoscaler
      k8s:
        state: present
        definition:
          apiVersion: autoscaling.openshift.io/v1beta1
          kind: MachineAutoscaler
          metadata:
            name: "{{ item.0 }}-us-east-2{{ item.1 }}"
            namespace: openshift-machine-api
          spec:
            minReplicas: 1
            maxReplicas: 2
            scaleTargetRef:
              apiVersion: machine.openshift.io/v1beta1
              kind: MachineSet
              name: "{{ infra_info.resources[0].status.infrastructureName }}-{{ item.0 }}-us-east-2{{ item.1 }}"
      with_nested:
        - ['infra', 'ocs', 'worker']
        - ['a', 'b', 'c']

- name: Install Cluster Logging
  block:
    - name: Create openshift-operators-redhat namespace
      k8s:
        state: present
        definition:
          apiVersion: v1
          kind: Namespace
          metadata:
            name: openshift-operators-redhat
            annotations:
              openshift.io/node-selector: node-role.kubernetes.io/infra=
              scheduler.alpha.kubernetes.io/defaultTolerations: '[{"operator": "Exists"}]'
            labels:
              openshift.io/cluster-monitoring: "true"
    - name: Create openshift-logging namespace
      k8s:
        state: present
        definition:
          apiVersion: v1
          kind: Namespace
          metadata:
            name: openshift-logging
            annotations:
              openshift.io/node-selector: ""
            labels:
              openshift.io/cluster-monitoring: "true"
    - name: Join the netnamespaces of logging projects
      command:
        argv:
          - oc
          - adm
          - pod-network
          - join-projects
          - --to=openshift-operators-redhat
          - openshift-logging
      when: clusternetwork.resources[0].pluginName == "redhat/openshift-ovs-multitenant"
    - name: Create openshift-operators-redhat OperatorGroup
      k8s:
        state: present
        definition:
          apiVersion: operators.coreos.com/v1
          kind: OperatorGroup
          metadata:
            name: openshift-operators-redhat
            namespace: openshift-operators-redhat
          spec: {}
    - name: Create elasticsearch-operator Subscription
      k8s:
        state: present
        definition:
          apiVersion: operators.coreos.com/v1alpha1
          kind: Subscription
          metadata:
            name: elasticsearch-operator
            namespace: openshift-operators-redhat
          spec:
            channel: "{{ clusterversion.resources[0].spec.channel.split('-')[1] }}"
            installPlanApproval: Automatic
            name: elasticsearch-operator
            source: redhat-operators
            sourceNamespace: openshift-marketplace
        wait: yes
        wait_condition:
          reason: AllCatalogSourcesHealthy
          type: CatalogSourcesUnhealthy
          status: "False"
    - name: Get elasticsearch-operator Subscription info
      k8s_info:
        api_version: operators.coreos.com/v1alpha1
        kind: Subscription
        name: elasticsearch-operator
        namespace: openshift-operators-redhat
      register: es_sub_info
    - name: Wait for CSV creation
      debug:
        msg: "Waiting for CSV creation..."
      until: es_sub_info.resources[0].status.currentCSV is defined
      retries: 60
      delay: 1
    - name: Wait for successful elasticsearch-operator CSV
      k8s_info:
        api_version: operators.coreos.com/v1alpha1
        kind: ClusterServiceVersion
        name: "{{ es_sub_info.resources[0].status.currentCSV }}"
        namespace: openshift-operators-redhat
      register: es_csv_info
      until:
        - es_csv_info.resources[0].status.phase is defined
        - es_csv_info.resources[0].status.phase == "Succeeded"
      retries: 60
      delay: 1
    - name: Create openshift-logging OperatorGroup
      k8s:
        state: present
        definition:
          apiVersion: operators.coreos.com/v1
          kind: OperatorGroup
          metadata:
            name: openshift-logging
            namespace: openshift-logging
          spec:
            targetNamespaces:
              - openshift-logging
    - name: Create cluster-logging Subscription
      k8s:
        state: present
        definition:
          apiVersion: operators.coreos.com/v1alpha1
          kind: Subscription
          metadata:
            name: cluster-logging
            namespace: openshift-logging
          spec:
            channel: "{{ clusterversion.resources[0].spec.channel.split('-')[1] }}"
            installPlanApproval: Automatic
            name: cluster-logging
            source: redhat-operators
            sourceNamespace: openshift-marketplace
        wait: yes
        wait_condition:
          reason: AllCatalogSourcesHealthy
          type: CatalogSourcesUnhealthy
          status: "False"
    - name: Get cluster-logging Subscription info
      k8s_info:
        api_version: operators.coreos.com/v1alpha1
        kind: Subscription
        name: cluster-logging
        namespace: openshift-logging
      register: logging_sub_info
    - name: Wait for CSV creation
      debug:
        msg: "Waiting for CSV creation..."
      until: logging_sub_info.resources[0].status.currentCSV is defined
      retries: 60
      delay: 1
    - name: Wait for successful cluster-logging CSV
      k8s_info:
        api_version: operators.coreos.com/v1alpha1
        kind: ClusterServiceVersion
        name: "{{ logging_sub_info.resources[0].status.currentCSV }}"
        namespace: openshift-logging
      register: logging_csv_info
      until:
        - logging_csv_info.resources[0].status.phase is defined
        - logging_csv_info.resources[0].status.phase == "Succeeded"
      retries: 60
      delay: 1
    - name: Create Cluster Logging instance
      k8s:
        state: present
        definition: "{{ lookup('file', 'cluster-logging-instance.yml') }}"

